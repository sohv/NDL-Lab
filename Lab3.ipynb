{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aedc372e-8f9a-4300-bbbf-b4af52745828",
   "metadata": {},
   "source": [
    "# Perceptron Algorithm for AND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "611b3c91-e389-4f28-9044-c080225dd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights and bias globally\n",
    "w1, w2, b = 0.5, 0.5, -1\n",
    "def activate(x):\n",
    "    return 1 if x>=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da21b44f-d265-48ee-96c5-0b85c60836db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs, outputs, lr, epochs):\n",
    "    global w1, w2, b\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(inputs)):\n",
    "            A,B = inputs[i]\n",
    "            target_output = outputs[i]\n",
    "            output = activate(w1*A + w2*B + b)\n",
    "            error = target_output - output\n",
    "            w1+= lr*error*A\n",
    "            w2+= lr*error*B\n",
    "            b+= lr*error\n",
    "            total_error += abs(error)\n",
    "        if total_error == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8890ec8-5dc3-4f4f-94c9-c32a70386ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs and desired outputs for AND gate\n",
    "inputs = [(0,0),(0,1),(1,0),(1,1)]\n",
    "desired_outputs = [0,0,0,1]\n",
    "lr = 0.1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9052e456-7cb5-4553-abdb-aac248656e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and Output for AND gate\n",
      "Input: (0, 0) Output: 0\n",
      "Input: (0, 1) Output: 0\n",
      "Input: (1, 0) Output: 0\n",
      "Input: (1, 1) Output: 1\n"
     ]
    }
   ],
   "source": [
    "train(inputs, desired_outputs, lr,epochs)\n",
    "print(\"Input and Output for AND gate\")\n",
    "for i in range(len(inputs)):\n",
    "    A,B = inputs[i]\n",
    "\n",
    "    output = activate(w1*A + w2*B +b)\n",
    "    print(f\"Input: ({A}, {B}) Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5c0ac-8ac7-40ea-80d0-63228924f57f",
   "metadata": {},
   "source": [
    "# OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c16e020-4cef-4b3b-ba1f-53b95ed9fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs and desired outputs for AND gate\n",
    "inputs_or = [(0,0),(0,1),(1,0),(1,1)]\n",
    "desired_outputs_or = [0,1,1,1]\n",
    "lr_or = 0.1\n",
    "epochs_or = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eee2f40-5a45-4d2a-99db-a5ef288ba7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and Output for OR gate\n",
      "Input: (0, 0) Output: 0\n",
      "Input: (0, 1) Output: 1\n",
      "Input: (1, 0) Output: 1\n",
      "Input: (1, 1) Output: 1\n"
     ]
    }
   ],
   "source": [
    "train(inputs_or, desired_outputs_or, lr_or,epochs_or)\n",
    "print(\"Input and Output for OR gate\")\n",
    "for i in range(len(inputs)):\n",
    "    A,B = inputs[i]\n",
    "\n",
    "    output = activate(w1*A + w2*B +b)\n",
    "    print(f\"Input: ({A}, {B}) Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f211b9e-4ba4-4c50-839f-7a109a2aaffa",
   "metadata": {},
   "source": [
    "# NAND gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a850a77-99c6-4976-8bdd-537d6ee0a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs and desired outputs for NAND gate\n",
    "inputs_nand = [(0,0),(0,1),(1,0),(1,1)]\n",
    "desired_outputs_nand = [1,1,1,0]\n",
    "lr_nand = 0.1\n",
    "epochs_nand = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85335878-7166-4130-b649-ffc1c6a9eca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and Output for NAND gate\n",
      "Input: (0, 0) Output: 1\n",
      "Input: (0, 1) Output: 1\n",
      "Input: (1, 0) Output: 1\n",
      "Input: (1, 1) Output: 0\n"
     ]
    }
   ],
   "source": [
    "train(inputs_nand, desired_outputs_nand, lr_nand,epochs_nand)\n",
    "print(\"Input and Output for NAND gate\")\n",
    "for i in range(len(inputs)):\n",
    "    A,B = inputs[i]\n",
    "\n",
    "    output = activate(w1*A + w2*B +b)\n",
    "    print(f\"Input: ({A}, {B}) Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9117c-e1d9-4db2-9aab-5acca4faa254",
   "metadata": {},
   "source": [
    "# NOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "072a46a0-0195-4a41-b9f9-375a98da78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs and desired outputs for NAND gate\n",
    "inputs_nor = [(0,0),(0,1),(1,0),(1,1)]\n",
    "desired_outputs_nor = [1,0,0,0]\n",
    "lr_nor = 0.1\n",
    "epochs_nor = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b28b24fa-a1b5-4cbf-819e-93dc73943e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and Output for NOR gate\n",
      "Input: (0, 0) Output: 1\n",
      "Input: (0, 1) Output: 0\n",
      "Input: (1, 0) Output: 0\n",
      "Input: (1, 1) Output: 0\n"
     ]
    }
   ],
   "source": [
    "train(inputs_nor, desired_outputs_nor, lr_nor,epochs_nor)\n",
    "print(\"Input and Output for NOR gate\")\n",
    "for i in range(len(inputs)):\n",
    "    A,B = inputs[i]\n",
    "\n",
    "    output = activate(w1*A + w2*B +b)\n",
    "    print(f\"Input: ({A}, {B}) Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a03f7-0996-4d94-982f-8e92f5e48aec",
   "metadata": {},
   "source": [
    "# XOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31eff962-30bf-4534-a157-5e216d74fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs and desired outputs for XOR gate\n",
    "inputs_xor = [(0,0),(0,1),(1,0),(1,1)]\n",
    "desired_outputs_xor = [0,1,1,0]\n",
    "lr_xor = 0.1\n",
    "epochs_xor = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "148045dc-4703-46e7-a73b-e3be072fee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input and Output for XOR gate\n",
      "Input: (0, 0) Output: 1\n",
      "Input: (0, 1) Output: 0\n",
      "Input: (1, 0) Output: 0\n",
      "Input: (1, 1) Output: 0\n"
     ]
    }
   ],
   "source": [
    "train(inputs_nor, desired_outputs_nor, lr_nor,epochs_nor)\n",
    "print(\"Input and Output for XOR gate\")\n",
    "for i in range(len(inputs)):\n",
    "    A,B = inputs[i]\n",
    "\n",
    "    output = activate(w1*A + w2*B +b)\n",
    "    print(f\"Input: ({A}, {B}) Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8275c-959b-4fe4-af97-e53ad8271742",
   "metadata": {},
   "source": [
    "The output above doesn't match with the expected outputs as a single-layer perceptron cannot solve the XOR problem. The XOR function is not linearly separable, which means a simple perceptron (a single-layer neural network) cannot find a linear decision boundary that separates the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9c2433-6e4d-4efa-a400-f323cc269283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE: 0.3416566429432655\n",
      "Epoch 1000, MSE: 0.24526110471683166\n",
      "Epoch 2000, MSE: 0.20917631103604314\n",
      "Epoch 3000, MSE: 0.15100917900432395\n",
      "Epoch 4000, MSE: 0.08611016219902304\n",
      "Epoch 5000, MSE: 0.03572932274685794\n",
      "Epoch 6000, MSE: 0.01940163810114008\n",
      "Epoch 7000, MSE: 0.0129576216715754\n",
      "Epoch 8000, MSE: 0.009662290598022951\n",
      "Epoch 9000, MSE: 0.007686705946790915\n",
      "\n",
      "Final predictions after training:\n",
      "[[0.10125271]\n",
      " [0.92688325]\n",
      " [0.92005246]\n",
      " [0.05933504]]\n",
      "\n",
      "Rounded predictions (binary):\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# inputs and expected output\n",
    "inputs = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "expected_outputs = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "input_layer_size = 2  # number of inputs\n",
    "hidden_layer_size = 4  # number of neurons in the hidden layer\n",
    "output_layer_size = 1  # output layer has only one neuron for binary classification\n",
    "\n",
    "# randomly initialize weights\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.rand(input_layer_size, hidden_layer_size)  # assign weights for the input to hidden layer\n",
    "weights_hidden_output = np.random.rand(hidden_layer_size, output_layer_size)  # assign weights for the hidden to output layer\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "# training process\n",
    "for epoch in range(epochs):\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)  # linear transformation from hidden to output\n",
    "    predicted_output = sigmoid(output_layer_input)  # apply sigmoid activation function\n",
    "\n",
    "    # backpropagation\n",
    "    # compute the error in output\n",
    "    error = y - predicted_output \n",
    "\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # update the weights using the gradients\n",
    "    weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
    "    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        mse = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, MSE: {mse}\")\n",
    "\n",
    "print(\"\\nFinal predictions after training:\")\n",
    "print(predicted_output)\n",
    "predicted_output_rounded = (predicted_output > 0.5).astype(int)\n",
    "print(\"\\nRounded predictions (binary):\")\n",
    "print(predicted_output_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69539246-003a-44d3-86d0-242c0d1ab476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204d10a-e20b-4f2c-9352-0dd2dbf303f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
